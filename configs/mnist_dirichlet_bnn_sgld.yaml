defaults:
  - dataset: mnist
  - model: mlp
  - training: bnn_sgld
  - _self_

seed: 1

model:
  params:
    output_layer_config:
      type: dirichlet
      params:
        num_classes: 10

training:
  device: cpu
  num_epochs: 10

  wandb:
    name: edl_mnist_bnn_sgld

  loss:
    name: evidential_classification
    params:
      lamb: 0.01

  likelihood:
    name: dirichlet

  prior:
    name: dirichlet_strength
    sd: 1.0
    a: 2.0
    b: 0.1
    normalize: false

  optimizer:
    name: sgld
    lr: 1e-1       
    temperature: 1.0 

  evaluation:
    train:
      interval: 0
    val:
      interval: 0
    test:
      interval: 1
      metrics:
        - name: accuracy
        - name: bma_dirichlet_accuracy
        - name: loss 
        - name: vacuity
        - name: dirichlet_strength
        - name: dirichlet_nll
        - name: bma_dirichlet_nll
        - name: dirichlet_brier_score
        - name: bma_dirichlet_brier_score
        - name: bma_dirichlet_calibration_error
          params:
            num_classes: 10
            num_bins: 15
            norm: l1

# Override: add flatten transform for MLP
dataset:
  batch_size: 256
  num_workers: 0
  splits:
    train:
      fraction: 1.0
      transforms:
        - name: to_tensor
        - name: normalize
          params:
            mean: [0.1307]
            std: [0.3081]
        - name: flatten
    
    val:
      fraction: 0.0

    
    test:
      fraction: 1.0
      transforms:
        - name: to_tensor
        - name: normalize
          params:
            mean: [0.1307]
            std: [0.3081]
        - name: flatten